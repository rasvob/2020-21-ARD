{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.7.3-final"
    },
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "kernelspec": {
      "name": "python37364bit338dbb2cb8464efc9e0e4a7e5c7dfcb4",
      "display_name": "Python 3.7.3 64-bit"
    },
    "colab": {
      "name": "ds4_03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "86f2EBR75Itm"
      },
      "outputs": [],
      "source": [
        "# Data analysis 4 - Lecture 3\n",
        "\n",
        "This lecture is about introduction to CNNs.\n",
        "\n",
        "We use validating sets, and evaluate our models on CIFAR-10 dataset.\n",
        "\n",
        "Also we will try the TransferLearning simple/educational example where we use one model trained on a dataset and retrained only the final layer for different dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "Fi2Jwhs35Itq"
      },
      "outputs": [],
      "source": [
        "[Open in Google colab](https://colab.research.google.com/github/jplatos/2019-2020-da4/blob/master/ds4_03.ipynb)\n",
        "[Download from Github](https://raw.githubusercontent.com/jplatos/2019-2020-DA4/master/ds4_03.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import matplotlib.image as mpimg # images\n",
        "import numpy as np #numpy\n",
        "import tensorflow.compat.v2 as tf #use tensorflow v2 as a main \n",
        "import tensorflow.keras as keras # required for high level applications\n",
        "from sklearn.model_selection import train_test_split # split for validation sets\n",
        "from sklearn.preprocessing import normalize # normalization of the matrix\n",
        "from scipy.signal import convolve2d # convolutionof the 2D signals\n",
        "\n",
        "tf.version.VERSION"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "qutmR93t-uis"
      },
      "outputs": [],
      "source": [
        "# Defining terms for CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "ZCmwOM9q_4td"
      },
      "outputs": [],
      "source": [
        "## Convolution\n",
        "A convolution is defined as the integral of the product of the two functions after one is reversed and shifted. It is a mathmematical way how to analyze behavior of the functions and the relation between the functions.\n",
        "\n",
        "In image processing, **kernel** or **convolution matrix** or **mask** is a small matrix. In general the convolution in image processing is defined as:\n",
        "\n",
        "$$g(x, y) = \\omega * f(x,y) = \\sum_{s=-a}^{a}\\sum_{t=-b}^{b}\\omega(s,t)f(x-s, y-t)$$\n",
        "\n",
        "where $g(x,y)$ is filtered image, $f(x,y)$ is original image, $\\omega$ if the filter kernel. \n",
        "\n",
        "A kernel (also called a filter) is a smaller-sized matrix in comparison to the dimensions of the input image, that consists of real valued entries.\n",
        "\n",
        "![Example of the Convolution](https://raw.githubusercontent.com/jplatos/2019-2020-DA4/master/images/convolution_example.gif)\n",
        "\n",
        "### Example filters\n",
        "\n",
        "|Name|Definition|\n",
        "|----|:--------:|\n",
        "|Identity| $\\left[\\begin{matrix}0&0&0\\\\0&1&0\\\\0&0&0\\end{matrix}\\right]$|\n",
        "|Sobel vertical edge detection| $\\left[\\begin{matrix}+1&0&-1\\\\+2&0&-2\\\\+1&0&-1\\end{matrix}\\right]$|\n",
        "|Sobel horizontal edge detection| $\\left[\\begin{matrix}+1&+2&+1\\\\0&0&0\\\\-1&-2&-1\\end{matrix}\\right]$|\n",
        "|Edge detection| $\\left[\\begin{matrix}-1&-1&-1\\\\-1&8&-1\\\\-1&-1&-1\\end{matrix}\\right]$|\n",
        "|Sharpen| $\\left[\\begin{matrix}0&-1&0\\\\-1&5&-1\\\\0&-1&0\\end{matrix}\\right]$|\n",
        "|Uniform blur|$\\frac{1}{9}\\left[\\begin{matrix}1&1&1\\\\1&1&1\\\\1&1&1\\end{matrix}\\right]$|\n",
        "|Gaussian blur 3x3| $\\frac{1}{16}\\left[\\begin{matrix}1&2&1\\\\2&4&2\\\\1&2&1\\end{matrix}\\right]$|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "IsiIQveNL991"
      },
      "outputs": [],
      "source": [
        "## Padding\n",
        "\n",
        "One tricky issue when applying convolutional is losing pixels on the edges of our image. A straightforward solution to this problem is to add extra pixels around the boundary of our input image, which increases the effective size of the image.\n",
        "\n",
        "![Padding example](https://raw.githubusercontent.com/jplatos/2019-2020-DA4/master/images/padding_example.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "f_TpDPYXL-Cz"
      },
      "outputs": [],
      "source": [
        "### Practical example of convolution and padding without TF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
        "\n",
        "lena_img_url = 'https://raw.githubusercontent.com/jplatos/2019-2020-DA4/master/images/lena.png'\n",
        "img = rgb2gray(mpimg.imread(lena_img_url))\n",
        "img = img/255.0\n",
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(img, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "blur_mask = np.ones((3,3))/9.0\n",
        "mask = np.array([\n",
        "    [ 0,-1, 0],\n",
        "    [-1, 4,-1],\n",
        "    [ 0,-1, 0]\n",
        "    ]) \n",
        "\n",
        "img_blur = convolve2d(img, blur_mask, boundary='symm', mode='same')\n",
        "result = np.clip(convolve2d(img_blur, mask, boundary='symm', mode='same'), 0, 1)\n",
        "\n",
        "plt.imshow(result, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "4heY4fMFL9z3"
      },
      "outputs": [],
      "source": [
        "## Pooling\n",
        "\n",
        "Pooling is a way how to decrease the amount of information transfered from one layer to another.\n",
        "The standard way ho to do it is Average Pooling and Maximum Pooling.\n",
        "\n",
        "![MaxPooling example](https://raw.githubusercontent.com/jplatos/2019-2020-DA4/master/images/pooling_example.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "RKoUodQT5It4"
      },
      "outputs": [],
      "source": [
        "## Tensorflow implementation of the Convolution Neural Network\n",
        "\n",
        "### Some utility functions\n",
        "Here is some functions we will use later several times\n",
        "* **show_history** - show history of the **fit** method\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_history(history):\n",
        "    plt.figure()\n",
        "    for key in history.history.keys():\n",
        "        plt.plot(history.epoch, history.history[key], label=key)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "def show_example(train_x, train_y, class_names):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    for i in range(25):\n",
        "        plt.subplot(5,5,i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(train_x[i], cmap=plt.cm.binary)\n",
        "        plt.xlabel(class_names[train_y[i][0]])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "x6HHl9Cb5IuB"
      },
      "outputs": [],
      "source": [
        "#### Dataset load\n",
        "Importing dataset **CIFAR10** a collection of images 28x28 grayscale of typical clothes and accesories.\n",
        "Dataset is:\n",
        "* downloaded\n",
        "* splitted into train and test set\n",
        "* converted from the range <0,255> into <0, 1>\n",
        "* *train* is splitted into *train* and *validation* set \n",
        "* class names are defined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cifar is the basic dataset for image classifaction\n",
        "dataset = tf.keras.datasets.cifar10\n",
        "\n",
        "# data from any dataset are loaded using the load_Data function\n",
        "(train_x, train_y), (test_x, test_y) = dataset.load_data()\n",
        "\n",
        "# train_x = train_x/255.0\n",
        "# test_x = test_x/255.0\n",
        "\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# the data are in the form of 32x32 pixes with values 0-255.\n",
        "print('Train data shape: ', train_x.shape, train_y.shape)\n",
        "print('Validation data shape: ', valid_x.shape, valid_y.shape)\n",
        "print('Test data shape:  ', test_x.shape, test_y.shape)\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "class_count = len(class_names)\n",
        "print('Class count:', class_count, class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Show example images of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_example(train_x, train_y, class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "Uli2EHB85IuT"
      },
      "outputs": [],
      "source": [
        "#### Definition of the model\n",
        "The base model is defined as *Sequential* with 2 convolutional layers.\n",
        "\n",
        "Summarization of the model and compilation is done similarly as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(class_count)\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "uz_cLvzw5Iub"
      },
      "outputs": [],
      "source": [
        "#### Fit the model for defined number of epochs.\n",
        "Show the history of learning, evaluate the efficiency of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(train_x, train_y, validation_data=(valid_x, valid_y), epochs=5)\n",
        "\n",
        "show_history(history)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_x, test_y)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "El-aMWON5Iuo"
      },
      "outputs": [],
      "source": [
        "#### Vizualization of the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = model.predict(test_x)\n",
        "conf_matrix = np.zeros((class_count, class_count))\n",
        "for idx, pred in enumerate(predictions):\n",
        "    row = test_y[idx]\n",
        "    col = np.argmax(pred)\n",
        "    conf_matrix[row, col] += 1\n",
        "\n",
        "# print(conf_matrix)\n",
        "conf_matrix = normalize(conf_matrix, axis=1, norm='l1')\n",
        "# print(conf_matrix)\n",
        "\n",
        "plt.figure(figsize=(class_count,class_count))\n",
        "\n",
        "plt.imshow(conf_matrix)\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        text = plt.text(j, i, \"{:.2f}\".format(conf_matrix[i, j]), ha=\"center\", va=\"center\", color=\"w\")\n",
        "\n",
        "plt.xticks(range(class_count), class_names)\n",
        "plt.yticks(range(class_count), class_names)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()     "
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "myIgGem85IvT"
      },
      "outputs": [],
      "source": [
        "## Tasks for Lecture \n",
        "1. [Data augmentation](https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/) is used to expand the training dataset in order to improve the performance and ability of the model to generalize.\n",
        "2. Desing a model which will be able to classify **CIFAR10** with accuracy higher than **80%**.\n",
        "3. Try to work with MNIST and FashionMnist datasets asan image - 99% on **Mnist** is achievable using CNN, 94% on **Fashion-Mnist** too."
      ]
    }
  ]
}