{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ilthBvnZCQto"
   },
   "source": [
    "# Algorithms for Big Data - Exercise 11\n",
    "This lecture is focused on Generative Adversarial Networks for image generation.\n",
    "\n",
    "A generative adversarial network (GAN) is deployed to create unique images of handwritten digits. The generated images look like they're taken from the dataset (that is the purpose), but they are generated from scratch (actually, from noise) and are all unique.\n",
    "\n",
    "You can download the dataset from this course on [Github](https://github.com/rasvob/2020-21-ARD/tree/master/datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fi2Jwhs35Itq"
   },
   "source": [
    "[Open in Google colab](https://colab.research.google.com/github/rasvob/2020-21-ARD/blob/master/abd_11.ipynb)\n",
    "[Download from Github](https://github.com/rasvob/2020-21-ARD/blob/master/abd_11.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import matplotlib.image as mpimg # images\n",
    "import numpy as np #numpy\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v2 as tf #use tensorflow v2 as a main \n",
    "import tensorflow.keras as keras # required for high level applications\n",
    "from sklearn.model_selection import train_test_split # split for validation sets\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import normalize # normalization of the matrix\n",
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history(history):\n",
    "    plt.figure()\n",
    "    for key in history.history.keys():\n",
    "        plt.plot(history.epoch, history.history[key], label=key)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is GAN (Generative Adversarial Networks)?\n",
    "\n",
    "GAN is almost always explained like the case of a counterfeiter (Generative) and the police (Discriminator). Initially, the counterfeiter will show the police a fake money. The police says it is fake. The police gives feedback to the counterfeiter why the money is fake. The counterfeiter attempts to make a new fake money based on the feedback it received. The police says the money is still fake and offers a new set of feedback. The counterfeiter attempts to make a new fake money based on the latest feedback. The cycle continues indefinitely until the police is fooled by the fake money because it looks real.\n",
    "\n",
    "![model](https://github.com/rasvob/2020-21-ARD/raw/master/images/gan01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will work with MNIST data in this lecture again\n",
    "\n",
    "We will rescale the data into the [0,1] interval for easier training of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist is the basic dataset with handwritten digits\n",
    "dataset = tf.keras.datasets.mnist\n",
    "\n",
    "# data from any dataset are loaded using the load_Data function\n",
    "(X_train, y_train), (X_test, y_test) = dataset.load_data()\n",
    "\n",
    "X_train, y_train = np.concatenate([X_train, X_test]), np.concatenate([y_train, y_test])\n",
    "\n",
    "# Scale to <-1; 1>\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "\n",
    "# the data are in the form of 28x28 pixes with values 0-255.\n",
    "print('Train data shape: ', X_train.shape, y_train.shape)\n",
    "\n",
    "class_names = [str(x) for x in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show first 25 images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train[i], cmap=plt.cm.gray)\n",
    "    plt.xlabel(class_names[y_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN has two main parts - Discriminator and Generator\n",
    "\n",
    "## Discriminator\n",
    "A discriminator that tells how real an image is, is basically a deep Convolutional Neural Network (CNN). \n",
    "\n",
    "For MNIST Dataset, the input is an image (28 pixel x 28 pixel x 1 channel). The sigmoid output is a scalar value of the probability of how real the image is (0.0 is certainly fake, 1.0 is certainly real, anything in between is a gray area). \n",
    "\n",
    "The difference from a typical CNN is the absence of max-pooling in between layers. Instead, a strided convolution is used for downsampling. The activation function used in each CNN layer is a leaky ReLU. A dropout between 0.4 and 0.7 between layers prevent over fitting and memorization, but it is an optional feature.\n",
    "\n",
    "![disc](https://github.com/rasvob/2020-21-ARD/raw/master/images/gan02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "The generator synthesizes fake images. The fake image is generated from a N-dimensional noise (uniform distribution between -1.0 to 1.0, gaussian noise etc.) using the inverse of convolution, called transposed convolution. \n",
    "\n",
    "The activation function after each layer is a LeakyReLU. The output of the sigmoid/tanh at the last layer produces the fake image.\n",
    "\n",
    "![](https://github.com/rasvob/2020-21-ARD/raw/master/images/gan03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Model\n",
    "The adversarial model is just the generator-discriminator stacked together as shown in the figure below.\n",
    "\n",
    "![](https://raw.githubusercontent.com/rasvob/2020-21-ARD/master/images/gan04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Training is the most complex part of the GAN creation. We need to divide each batch to two halves, where one constains fake images generated by the Generator part of the network and the other contains real samples from MNIST dataset. \n",
    "\n",
    "It is common to disable discriminator training first and enable it only for the discriminator training phase. Afterwards it is disabled again and only the generator part of the network is trained.\n",
    "\n",
    "There are various trick for GAN training. Very nice list is at this [repo](https://github.com/soumith/ganhacks). The most important ones in the long run are input normalization, sampling from a gaussian distribution and avoiding Sparse Gradients: ReLU, MaxPool. \n",
    "\n",
    "It's also possible to use label smoothing. I.e. if you have two target labels: Real=1 and Fake=0, then for each incoming sample, if it is real, then replace the label with a random number between 0.7 and 1.2, and if it is a fake sample, replace it with 0.0 and 0.3 (for example). Alternatively you can use one-sided smoothing, i.e. you use 0.7-0.9 for real samples and hard-zero for fake ones.\n",
    "\n",
    "![](https://github.com/rasvob/2020-21-ARD/raw/master/images/gan05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will train two models in this lecture\n",
    "We will start with simle GAN in form of a fully-connected network. We will create another model basen on the CNN, called DCGAN later in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input dimension is an important hyper-parameter\n",
    "randomDim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will flatten the input\n",
    "X_mlp = X_train.reshape(X_train.shape[0], 28**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will create Discriminator part first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = keras.models.Sequential()\n",
    "discriminator.add(keras.layers.Dense(1024, input_dim=28**2, kernel_initializer=keras.initializers.RandomNormal(stddev=0.02)))\n",
    "discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "discriminator.add(keras.layers.Dropout(0.3))\n",
    "discriminator.add(keras.layers.Dense(512))\n",
    "discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "discriminator.add(keras.layers.Dropout(0.3))\n",
    "discriminator.add(keras.layers.Dense(256))\n",
    "discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "discriminator.add(keras.layers.Dropout(0.3))\n",
    "discriminator.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can create the Generator part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = keras.models.Sequential()\n",
    "generator.add(keras.layers.Dense(256, input_dim=randomDim, kernel_initializer=keras.initializers.RandomNormal(stddev=0.02)))\n",
    "generator.add(keras.layers.LeakyReLU(0.2))\n",
    "generator.add(keras.layers.Dense(512))\n",
    "generator.add(keras.layers.LeakyReLU(0.2))\n",
    "generator.add(keras.layers.Dense(1024))\n",
    "generator.add(keras.layers.LeakyReLU(0.2))\n",
    "generator.add(keras.layers.Dense(784, activation='tanh'))\n",
    "generator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined network into one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "ganInput = keras.layers.Input(shape=(randomDim,))\n",
    "x = generator(ganInput)\n",
    "ganOutput = discriminator(x)\n",
    "gan = keras.models.Model(inputs=ganInput, outputs=ganOutput)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(gan, expand_nested=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModels(epoch, name='gan'):\n",
    "    generator.save(f'models/{name}_generator_epoch_{epoch}')\n",
    "    discriminator.save(f'models/{name}_discriminator_epoch_{epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "batchSize=128\n",
    "batchCount = int(X_train.shape[0] / batchSize)\n",
    "    \n",
    "dLosses = []\n",
    "gLosses = []\n",
    "\n",
    "generated_images = {}\n",
    "generated_examples = 100\n",
    "\n",
    "for epoch in range(0, epochs+1):\n",
    "    print(f'----- Epoch: {epoch} -----')\n",
    "    for batch in tqdm(range(batchCount)):\n",
    "        # Get a random set of input noise and images\n",
    "        noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
    "        imageBatch = X_mlp[np.random.randint(0, X_train.shape[0], size=batchSize)]\n",
    "        \n",
    "        # Generate fake MNIST images and combine them with real ones\n",
    "        generatedImages = generator.predict(noise)\n",
    "        X = np.concatenate([imageBatch, generatedImages])\n",
    "        \n",
    "        # Labels for generated and real data\n",
    "        yDis = np.zeros(2*batchSize)\n",
    "        # One-sided label smoothing - real ones has values 0.9\n",
    "        yDis[:batchSize] = 0.9\n",
    "        \n",
    "        # Train discriminator\n",
    "        discriminator.trainable = True\n",
    "        dloss = discriminator.train_on_batch(X, yDis)\n",
    "        \n",
    "        # Train generator\n",
    "        noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
    "        yGen = np.ones(batchSize)\n",
    "        discriminator.trainable = False\n",
    "        gloss = gan.train_on_batch(noise, yGen)\n",
    "        \n",
    "    # Store loss of most recent batch from this epoch\n",
    "    dLosses.append(dloss)\n",
    "    gLosses.append(gloss)\n",
    "    \n",
    "    # Save models every 5 epochs\n",
    "    if epoch == 1 or epoch % 5 == 0:\n",
    "        saveModels(epoch)\n",
    "        noise = np.random.normal(0, 1, size=[generated_examples, randomDim])\n",
    "        generatedImages = generator.predict(noise)\n",
    "        generatedImages = generatedImages.reshape(generated_examples, 28, 28)\n",
    "        generated_images[epoch] = generatedImages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(dLosses, label='Discriminitive loss')\n",
    "plt.plot(gLosses, label='Generative loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See that the epochs were saved\n",
    "generated_images.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's take a look at some examples generated in different epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_examples(epoch=0):\n",
    "    selected_examples = generated_images[epoch]\n",
    "    dim = (10,10)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(selected_examples.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(selected_examples[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save/load TF2 API can be used to reconstruct the model identically.\n",
    "\n",
    "A Keras model consists of multiple components:\n",
    "- An architecture, or configuration, which specifies what layers the model contain, and how they're connected.\n",
    "- A set of weights values (the \"state of the model\").\n",
    "- An optimizer (defined by compiling the model).\n",
    "- A set of losses and metrics (defined by compiling the model or calling add_loss() or add_metric()).\n",
    "\n",
    "The Keras API makes it possible to save all of these pieces to disk at once, or to only selectively save some of them:\n",
    "- Saving everything into a single archive in the TensorFlow SavedModel format (or in the older Keras H5 format). This is the standard practice.\n",
    "- Saving the architecture / configuration only, typically as a JSON file.\n",
    "- Saving the weights values only. This is generally used when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"models/gan_generator_epoch_0\")\n",
    "\n",
    "noise = np.random.normal(0, 1, size=[100, randomDim])\n",
    "generatedImages = generator.predict(noise)\n",
    "generatedImages = generatedImages.reshape(generated_examples, 28, 28)\n",
    "\n",
    "dim = (10,10)\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(generatedImages.shape[0]):\n",
    "    plt.subplot(dim[0], dim[1], i+1)\n",
    "    plt.imshow(generatedImages[i], interpolation='nearest', cmap='gray_r')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we know the basics and we can move to more complex example - DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First reshape input data for CNN into (70000, 28, 28, 1) shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dc = X_train.reshape(70000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now define the model again, but now with CNN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomDim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "generator = keras.models.Sequential()\n",
    "generator.add(keras.layers.Dense(128*7*7, input_dim=randomDim, kernel_initializer=keras.initializers.RandomNormal(stddev=0.02)))\n",
    "generator.add(keras.layers.LeakyReLU(0.2))\n",
    "generator.add(keras.layers.Reshape((7, 7, 128)))\n",
    "generator.add(keras.layers.UpSampling2D(size=(2, 2)))\n",
    "generator.add(keras.layers.Conv2D(64, kernel_size=(5, 5), padding='same'))\n",
    "generator.add(keras.layers.LeakyReLU(0.2))\n",
    "generator.add(keras.layers.UpSampling2D(size=(2, 2)))\n",
    "generator.add(keras.layers.Conv2D(1, kernel_size=(5, 5), padding='same', activation='tanh'))\n",
    "generator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "discriminator = keras.models.Sequential()\n",
    "discriminator.add(keras.layers.Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding='same', input_shape=(28, 28, 1), kernel_initializer=keras.initializers.RandomNormal(stddev=0.02)))\n",
    "discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "discriminator.add(keras.layers.Dropout(0.3))\n",
    "discriminator.add(keras.layers.Conv2D(128, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
    "discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "discriminator.add(keras.layers.Dropout(0.3))\n",
    "discriminator.add(keras.layers.Flatten())\n",
    "discriminator.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined network\n",
    "discriminator.trainable = False\n",
    "ganInput = keras.layers.Input(shape=(randomDim,))\n",
    "x = generator(ganInput)\n",
    "ganOutput = discriminator(x)\n",
    "gan = keras.models.Model(inputs=ganInput, outputs=ganOutput)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(gan, expand_nested=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "batchSize=128\n",
    "batchCount = int(X_train.shape[0] / batchSize)\n",
    "    \n",
    "dLosses = []\n",
    "gLosses = []\n",
    "\n",
    "generated_images = {}\n",
    "generated_examples = 100\n",
    "\n",
    "for epoch in range(0, epochs+1):\n",
    "    print(f'----- Epoch: {epoch} -----')\n",
    "    for batch in tqdm(range(batchCount)):\n",
    "        # Get a random set of input noise and images\n",
    "        noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
    "        imageBatch = X_dc[np.random.randint(0, X_train.shape[0], size=batchSize)]\n",
    "        \n",
    "        # Generate fake MNIST images and combine them with real ones\n",
    "        generatedImages = generator.predict(noise)\n",
    "        X = np.concatenate([imageBatch, generatedImages])\n",
    "        \n",
    "        # Labels for generated and real data\n",
    "        yDis = np.zeros(2*batchSize)\n",
    "        # One-sided label smoothing - real ones has values 0.9\n",
    "        yDis[:batchSize] = 0.9\n",
    "        \n",
    "        # Train discriminator\n",
    "        discriminator.trainable = True\n",
    "        dloss = discriminator.train_on_batch(X, yDis)\n",
    "        \n",
    "        # Train generator\n",
    "        noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
    "        yGen = np.ones(batchSize)\n",
    "        discriminator.trainable = False\n",
    "        gloss = gan.train_on_batch(noise, yGen)\n",
    "        \n",
    "    # Store loss of most recent batch from this epoch\n",
    "    dLosses.append(dloss)\n",
    "    gLosses.append(gloss)\n",
    "    \n",
    "    # Save models every 5 epochs\n",
    "    if epoch == 1 or epoch % 5 == 0:\n",
    "        saveModels(epoch,'dcgan')\n",
    "        noise = np.random.normal(0, 1, size=[generated_examples, randomDim])\n",
    "        generatedImages = generator.predict(noise)\n",
    "        generatedImages = generatedImages.reshape(generated_examples, 28, 28)\n",
    "        generated_images[epoch] = generatedImages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(dLosses, label='Discriminitive loss')\n",
    "plt.plot(gLosses, label='Generative loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See that the epochs were saved\n",
    "generated_images.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's take a look at some examples generated in different epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ds4_04.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
