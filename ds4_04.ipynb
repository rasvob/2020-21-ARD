{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ilthBvnZCQto"
   },
   "source": [
    "# Data Science 4 - Lecture 4 \n",
    "This lecture is focused in more detailed understanding of the Convolution neural networks. \n",
    "\n",
    "The visualization and the response of the CNN layers will be intestigated and a proper.\n",
    "\n",
    "We will use the MNIST dataset but other may be used as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fi2Jwhs35Itq"
   },
   "source": [
    "[Open in Google colab](https://colab.research.google.com/github/jplatos/2019-2020-da4/blob/master/ds4_04.ipynb)\n",
    "[Download from Github](https://raw.githubusercontent.com/jplatos/2019-2020-DA4/master/ds4_04.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import matplotlib.image as mpimg # images\n",
    "import numpy as np #numpy\n",
    "import tensorflow.compat.v2 as tf #use tensorflow v2 as a main \n",
    "import tensorflow.keras as keras # required for high level applications\n",
    "from sklearn.model_selection import train_test_split # split for validation sets\n",
    "from sklearn.preprocessing import normalize # normalization of the matrix\n",
    "from scipy.signal import convolve2d # convolutionof the 2D signals\n",
    "\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history(history):\n",
    "    plt.figure()\n",
    "    for key in history.history.keys():\n",
    "        plt.plot(history.epoch, history.history[key], label=key)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "def show_example(train_x, train_y, class_names):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(train_x[i].reshape(28,28), cmap=plt.cm.binary)\n",
    "        plt.xlabel(class_names[train_y[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist is the basic dataset for image classifaction\n",
    "dataset = tf.keras.datasets.mnist\n",
    "\n",
    "# data from any dataset are loaded using the load_Data function\n",
    "(train_x, train_y), (test_x, test_y) = dataset.load_data()\n",
    "\n",
    "train_x = train_x.reshape(*train_x.shape, 1)\n",
    "test_x = test_x.reshape(*test_x.shape, 1)\n",
    "\n",
    "train_x = train_x/255.0\n",
    "test_x = test_x/255.0\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# the data are in the form of 32x32 pixes with values 0-255.\n",
    "print('Train data shape: ', train_x.shape, train_y.shape)\n",
    "print('Validation data shape: ', valid_x.shape, valid_y.shape)\n",
    "print('Test data shape:  ', test_x.shape, test_y.shape)\n",
    "\n",
    "# class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "class_names = [str(x) for x in range(10)]\n",
    "# class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "class_count = len(class_names)\n",
    "print('Class count:', class_count, class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o9cTfCd_dUYX"
   },
   "source": [
    "#### Show example images of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "colab_type": "code",
    "id": "E__wf-i8CQt0",
    "outputId": "4a455d2b-f595-4cb3-f1c4-fcdafeda7967"
   },
   "outputs": [],
   "source": [
    "show_example(train_x, train_y, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "omlMtFlgCuTj"
   },
   "source": [
    "### Create a well defined model \n",
    "\n",
    "The model is able achieve more the 99% precision on the validation as well as testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "colab_type": "code",
    "id": "GqGF8pxYCQt2",
    "outputId": "854e6ae7-1750-4e71-bb94-5f32ec9446d4"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(28,28,1)),\n",
    "    keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    keras.layers.Conv2D(16, (3,3), padding='same', activation='relu'),    \n",
    "    keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uz_cLvzw5Iub"
   },
   "source": [
    "#### Fit the model on the train data.\n",
    "Lets train the model on the training data and find the best model using the EarlyStopping callback to find the best model avaialble and achievable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PcNubiSECQt5"
   },
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=7, restore_best_weights=True)\n",
    "history = model.fit(train_x, train_y, validation_data=(valid_x, valid_y), callbacks=[es], epochs=50)\n",
    "\n",
    "show_history(history)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_x, test_y)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCnIUespE4P2"
   },
   "source": [
    "## Visualize the layers\n",
    "Lest see what the network was able to learn from the train data. For that, we need to prepare a new model and see the ouputs of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m0fMPy-_rdcB"
   },
   "outputs": [],
   "source": [
    "# get the outputs form all layers in the model\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "# create the model that has single input and as an output all the outputs from the layers. \n",
    "# Because the layers are connected then the output from first layer is propagated into second layer and the output is computed o it.\n",
    "activation_model = keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "# get all the outputs from the model for 10-th input\n",
    "activations = activation_model.predict(train_x[10].reshape(1,28,28,1))\n",
    " \n",
    "# this functions shows the output from each filters\n",
    "def display_activation(activations, col_size, row_size, act_index): \n",
    "    activation = activations[act_index]\n",
    "    activation_index=0\n",
    "    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))\n",
    "    for row in range(0,row_size):\n",
    "        for col in range(0,col_size):\n",
    "            ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\n",
    "            activation_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "qn1tQ1v1ulrj",
    "outputId": "ec7f97ad-743a-491a-eb63-ddd656065d93"
   },
   "outputs": [],
   "source": [
    "# show the input image\n",
    "plt.imshow(train_x[10][:,:,0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "colab_type": "code",
    "id": "RMEV2Qjpu98v",
    "outputId": "42a09ea4-126b-4c45-aef2-06f42253db67"
   },
   "outputs": [],
   "source": [
    "# show the output from the first layer - CNN2D\n",
    "display_activation(activations, 8, 8, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 702
    },
    "colab_type": "code",
    "id": "FUWTBNVEvkhk",
    "outputId": "e6ed2884-1a69-42ac-d8f9-e8a45561349d"
   },
   "outputs": [],
   "source": [
    "# show the second convolution layer\n",
    "display_activation(activations, 8, 8, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "g3rY1W9Jv5cI",
    "outputId": "81d549c6-2a27-4d9b-c288-c29d76c592f6"
   },
   "outputs": [],
   "source": [
    "# show the third activation layer\n",
    "display_activation(activations, 4, 4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BL5RP5_ELJda"
   },
   "source": [
    "## The weights of each layer\n",
    "The weight can be extracted from layer as a tuple of weights and biasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3pMxsTroyYV6",
    "outputId": "71657a02-b52c-497d-a35b-eca3e64fe6db"
   },
   "outputs": [],
   "source": [
    "filters, biases = model.layers[0].get_weights()\n",
    "print(filters.shape, biases.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DtRVA3rbLXns"
   },
   "outputs": [],
   "source": [
    "#### The weidhts may be normalized in to 0-1 interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wD_ChuZl0oss"
   },
   "outputs": [],
   "source": [
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "MLxVm4H207Kz",
    "outputId": "a8bf4a97-b64a-4b4d-f7b8-8de6c1c53e5a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# plot first few filters\n",
    "n_filters = 64\n",
    "for i in range(n_filters):\n",
    "    # get the filter\n",
    "    f = filters[:, :, :, i]\n",
    "    # plot each channel separately\n",
    "    # specify subplot and turn of axis\n",
    "    ax = plt.subplot(8, 8, i+1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # plot filter channel in grayscale\n",
    "    plt.imshow(f[:, :, 0], cmap='gray')\n",
    "  \n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tGJ5tWyS3_TQ"
   },
   "source": [
    "## Autoencoder\n",
    "The autoencoder is a special type of neural network that is able to learn without the classes just from the input data. It is equivalent to the feature extraction from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 723
    },
    "colab_type": "code",
    "id": "QuVpJVK94DFp",
    "outputId": "afbc8c89-4d92-468a-eae5-13498cc813f7"
   },
   "outputs": [],
   "source": [
    "autoencoder = keras.Sequential([\n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(28,28,1)),\n",
    "    keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    keras.layers.Conv2D(8, (3,3), padding='same', activation='relu'),    \n",
    "    keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    # a 128 values of the minimized knowledge / features\n",
    "    keras.layers.Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    keras.layers.UpSampling2D((2,2)),\n",
    "    keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "    keras.layers.UpSampling2D((2,2)),\n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    keras.layers.UpSampling2D((2,2)),\n",
    "    \n",
    "    keras.layers.Conv2D(1, (3,3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qWU9bNYvEj0B"
   },
   "source": [
    "### Fit the model\n",
    "The model may be fitted as much as possible, this model converges but slowly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gTlUF95g74Ix",
    "outputId": "62d8c7ef-2f8b-47f0-d1dc-fe9b5c3ec93d"
   },
   "outputs": [],
   "source": [
    "history = autoencoder.fit(train_x, train_x, validation_data=(valid_x, valid_x), epochs=50)\n",
    "\n",
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-t0IRJqGSh3"
   },
   "source": [
    "### Generate original and reconstructed images\n",
    "The autoencoder fits on the original data on input as well as on output, therefore it is possible to generate reconstructed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "B13tGF3soCGg",
    "outputId": "7a8fdc04-3c00-468a-e5b5-744fc01671cc"
   },
   "outputs": [],
   "source": [
    "predicted = autoencoder.predict(test_x)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(test_x[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1+n)\n",
    "    plt.imshow(predicted[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FW3TBKwrHPHj"
   },
   "source": [
    "### Vizualize the encoded vectors\n",
    "The vectors that are generated by the encoder may be vizualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "Bc9Gwgg6pj5-",
    "outputId": "d86a5d67-cccf-4df3-90a8-371e9159a991"
   },
   "outputs": [],
   "source": [
    "encoder = keras.Sequential([\n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(28,28,1)),\n",
    "    keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    keras.layers.Conv2D(8, (3,3), padding='same', activation='relu'),    \n",
    "    keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "])\n",
    "\n",
    "# encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "encoder.set_weights(autoencoder.get_weights()[:6])\n",
    "\n",
    "for layer in encoder.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "id": "c2AKBMZqop2J",
    "outputId": "2b1207ae-7bcd-4d55-a83e-179841fc9137"
   },
   "outputs": [],
   "source": [
    "encoded = encoder.predict(test_x)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 8))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(encoded[i].reshape(8, 16).T)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax = plt.subplot(2, n, n+i+1)\n",
    "    plt.imshow(test_x[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8D6okcRKNGr"
   },
   "source": [
    "### Is the encoder better than the previous one?\n",
    "The encoder generated using the autoencoder principle generate a compressed representation of the input. The inner vector with 128 values is much smaller and the goal of the autoencoder is different than from the classifier, therefore the generated representation is usually better using the classifier directly.\n",
    "Some variants of encoder are able to generate better representation - a sparse autoencoders that generate sparse representation for exmaple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17_ESVZavDRH"
   },
   "outputs": [],
   "source": [
    "\n",
    "encoder.add(keras.layers.Flatten())\n",
    "encoder.add(keras.layers.Dense(64, activation='relu'))\n",
    "encoder.add(keras.layers.Dropout(0.25))\n",
    "encoder.add(keras.layers.Dense(32, activation='relu'))\n",
    "encoder.add(keras.layers.Dropout(0.25))\n",
    "encoder.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 566
    },
    "colab_type": "code",
    "id": "v1XCcy80ASJq",
    "outputId": "7323848c-d337-4285-9c04-91e66b982d5c"
   },
   "outputs": [],
   "source": [
    "encoder.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794
    },
    "colab_type": "code",
    "id": "jDKSZrl6wII7",
    "outputId": "67278acc-518e-49e8-87bb-c41fc55135e2"
   },
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=7, restore_best_weights=True)\n",
    "\n",
    "history = encoder.fit(train_x, train_y, validation_data=(valid_x, valid_y), callbacks = [es], epochs=50)\n",
    "\n",
    "show_history(history)\n",
    "\n",
    "test_loss, test_acc = encoder.evaluate(test_x, test_y)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TnnRMaEcPi1w"
   },
   "source": [
    "## Denoising-autoencoder\n",
    "The denoising autoencoder is a autoencoder that will learn how to remove random noise from the images. \n",
    "\n",
    "First, noisy images have to be generated. \n",
    "\n",
    "Then the autoencoder need to be created and trained. \n",
    "\n",
    "Then denosed images may be reconstructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.5\n",
    "noisy_train_x = np.clip(train_x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=train_x.shape), 0., 1.)\n",
    "noisy_valid_x = np.clip(valid_x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=valid_x.shape), 0., 1.)\n",
    "noisy_test_x = np.clip(test_x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=test_x.shape), 0., 1.) \n",
    "\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(2*n, 4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(train_x[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax = plt.subplot(2, n, n+i+1)\n",
    "    plt.imshow(noisy_train_x[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "myIgGem85IvT"
   },
   "source": [
    "## Tasks for Lecture / Exercise\n",
    "1. Implement the autoencoder that do something usefull like denoising, implement it on the data defined above.\n",
    "2. The Keras contains stored models that may be used for classification. The pretrained models may be used effectivelly to classify data, e.g. images, using the state of the art models. Try to investigate the architecture of the stored models and use the for classification of sample data downloaded from the internet.\n",
    "  1. Try VGG16 model and investigrate its architecture.\n",
    "  2. Try ResNet model architecture."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ds4_04.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
